{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Diabetes Diagnosis through Machine Learning: Investigating Algorithms and Data Augmentation for Class Imbalanced BRFSS Dataset"
      ],
      "metadata": {
        "id": "f9mcVr0lBGp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 Sampling and Encoding the dataset"
      ],
      "metadata": {
        "id": "LTGTgYTIOmAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Load the dataset with appropritate fields (Final Dataset)"
      ],
      "metadata": {
        "id": "zRpahf06BbPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT7BPtSpBCi3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "initial_data = pd.read_csv('/content/data/final_diabetes_data.csv') # update the path as needed\n",
        "filtered_df = initial_data[~initial_data['_AGEG5YR'].isin([1,2,3,4])]\n",
        "filtered_df = filtered_df.drop(['_RFHYPE6'],axis = 1)\n",
        "data = filtered_df.copy()\n",
        "data = data.astype('category')\n",
        "[not_diabetes, diabetes] = data[\"DIABETE4\"].value_counts()\n",
        "print({\"not_diabetes\":not_diabetes, \"diabetes\": diabetes})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this it is evident that, there is a class imbalance in the dataset, and we need to resolve this issue to make a better classifier. In this notebook we will use undersampling data augmentation technique to resolve this issue."
      ],
      "metadata": {
        "id": "_3KVJxHuEo5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Splitting tha dataset to train and test"
      ],
      "metadata": {
        "id": "WD-xFuY3N9E-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For undersampling, we will split the dataset in 80:20 ratio of training and testing data. The data is shuffled by default and splited in a stratified fashion."
      ],
      "metadata": {
        "id": "J_ieODcQFKj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop(columns = ['DIABETE4'])\n",
        "y = data['DIABETE4']\n",
        "y.replace({3: 0}, inplace=True) # to set the 3 to 0 category\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n",
        "[not_diabetes, diabetes] = y_train.value_counts()\n",
        "print({\"not_diabetes\":not_diabetes, \"diabetes\": diabetes})"
      ],
      "metadata": {
        "id": "jMx9jkMjFCtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The not_diabetes is set as 3 and diabetes is set as 1 in the final dataset, so we replaced 3 with 0. Tt is evident that the ratio is well maintained after the split."
      ],
      "metadata": {
        "id": "PX4vdQroGJNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Undersampling the training dataset"
      ],
      "metadata": {
        "id": "XKVG455GOBqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "# Create an instance of the ENN algorithm with Jaccard distance metric\n",
        "enn = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=7, kind_sel='all',\n",
        "                              n_jobs=1)\n",
        "\n",
        "X_resampledenn, y_resampledenn = enn.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "9FV3hwxPHSmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[not_diabetes, diabetes] = y_train.value_counts()\n",
        "print(\"Original dataset shape:\", {\"not_diabetes\":not_diabetes, \"diabetes\": diabetes})\n",
        "[not_diabetes, diabetes] = y_resampledenn.value_counts()\n",
        "print(\"Resampled dataset shape:\", {\"not_diabetes\":not_diabetes, \"diabetes\": diabetes})"
      ],
      "metadata": {
        "id": "1jwqlKGdLfkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Encoding the datset using One Hot Encoding\n",
        "After sampling, to create a classifier we need to encode the categorical data to one hot encoding."
      ],
      "metadata": {
        "id": "4VYVry3UOHlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def one_hot(X_resampled, X_test):\n",
        "  train_df = X_resampled.copy()\n",
        "  test_df = X_test.copy()\n",
        "  ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "  ohe.fit(train_df)\n",
        "  train_encoded = ohe.transform(train_df)\n",
        "  ohe.fit(test_df)\n",
        "  test_encoded = ohe.transform(test_df)\n",
        "\n",
        "# Create DataFrame of encoded features\n",
        "  train_encoded_df = pd.DataFrame(train_encoded, columns=ohe.get_feature_names_out(train_df.columns))\n",
        "  test_encoded_df = pd.DataFrame(test_encoded, columns=ohe.get_feature_names_out(test_df.columns))\n",
        "\n",
        "# Concatenate encoded features with original datasets\n",
        "  return train_encoded_df, test_encoded_df\n",
        "\n",
        "[train_final_enn, test_final_enn] = one_hot(X_resampledenn, X_test)"
      ],
      "metadata": {
        "id": "1y89CnPwIPc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Save the sampled and encoded data for future use."
      ],
      "metadata": {
        "id": "g9YANH32OQWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_final_enn.to_csv('/content/data/X_train_under_enn.csv', index=False)\n",
        "test_final_enn.to_csv('/content/data/X_test_under_enn.csv',index=False)\n",
        "y_resampledenn.to_csv('/content/data/y_train_under_enn.csv', index=False)\n",
        "y_test.to_csv('/content/data/y_test_under_enn.csv', index=False)"
      ],
      "metadata": {
        "id": "f3RFKS0XIoEN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 Developing the classifiers"
      ],
      "metadata": {
        "id": "2mLTLLgTOgt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Load necessary packages, utility functions and data"
      ],
      "metadata": {
        "id": "KKC_LDIdOcEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean, stdev\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,roc_auc_score,classification_report,auc,roc_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fmmIsqtoOWTd"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('/content/data/X_train_under_enn.csv')\n",
        "X_test = pd.read_csv('/content/data/X_test_under_enn.csv')\n",
        "y_train = pd.read_csv('/content/data/y_train_under_enn.csv')\n",
        "y_test = pd.read_csv('/content/data/y_test_under_enn.csv')"
      ],
      "metadata": {
        "id": "WbpwDvwjN6Do"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_test, y_pred,y_pred_proba):\n",
        "    precision = precision_score(y_test,y_pred,average='macro')\n",
        "    recall = recall_score(y_test,y_pred,average='macro')\n",
        "    accuracy = accuracy_score(y_test,y_pred,)\n",
        "    f1 = f1_score(y_test,y_pred,average='macro')\n",
        "    rocauc_score = roc_auc_score(y_test,y_pred_proba, average=None)\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc_curve = auc(fpr, tpr)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,fpr,tpr"
      ],
      "metadata": {
        "id": "EWA92pCNQGei"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_report(precisions,recalls,accurecies,f1_scores,rocauc_score,report,roc_auc_curve):\n",
        "  print('List of possible precision:', precisions)\n",
        "  print('List of possible recall:', recalls)\n",
        "  print('List of possible accuracy:', accurecies)\n",
        "  print('List of possible f1_score:', f1_scores)\n",
        "  print('ROC AUC: %.3f' % rocauc_score)\n",
        "  print('ROC_AUC_CURVE: %.3f' % roc_auc_curve)\n",
        "  print(report)"
      ],
      "metadata": {
        "id": "Lp0DpV_6QNsC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Logistic regression (LR)"
      ],
      "metadata": {
        "id": "ry6FhDiWQZ7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# training\n",
        "lr = LogisticRegression(C= 0.1, class_weight= 'balanced', fit_intercept= True, max_iter= 10000, penalty='l2', solver= 'newton-cg', warm_start= True,random_state = 42 )\n",
        "lr.fit(X_train, np.ravel(y_train))\n",
        "y_pred = lr.predict(X_test)\n",
        "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# model evaluation report\n",
        "[precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,lr_fpr,lr_tpr] = evaluate_model(y_test ,y_pred,y_pred_proba)\n",
        "model_report(precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve)\n",
        "plt.plot(lr_fpr,lr_tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_LR_undersampled_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8wMEEORmQSbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Random Forest Classifier (RFC)\n"
      ],
      "metadata": {
        "id": "wZIoqjjhWr3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model training\n",
        "rfc = RandomForestClassifier(criterion= 'gini', max_depth= None, max_features= None, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 20000, random_state=42)\n",
        "rfc.fit(X_train, np.ravel(y_train))\n",
        "y_pred = rfc.predict(X_test)\n",
        "y_pred_proba = rfc.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# model evaluation\n",
        "[precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,rf_fpr,rf_tpr] = evaluate_model(y_test ,y_pred,y_pred_proba)\n",
        "model_report(precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve)\n",
        "plt.plot(rf_fpr,rf_tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_RF_undersampled_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bzyfbb97WxBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Gradient Boosting Classifier (GBC)\n"
      ],
      "metadata": {
        "id": "Jiik37i3T7Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# train model\n",
        "gbm = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_features= 'log2', n_estimators= 1000,random_state = 42 )\n",
        "\n",
        "gbm.fit(X_train, np.ravel(y_train))\n",
        "y_pred =gbm.predict(X_test)\n",
        "y_pred_proba = gbm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# model evaluation report\n",
        "[precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,gb_fpr,gb_tpr] = evaluate_model(y_test ,y_pred,y_pred_proba)\n",
        "model_report(precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve)\n",
        "plt.plot(gb_fpr,gb_tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_GBC_undersampled_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GkAwsgT-T_vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Ada Boosting Classifier (ADA)"
      ],
      "metadata": {
        "id": "GAv1qpWPUsgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# train model\n",
        "ada = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 1, n_estimators= 20000,random_state=42)\n",
        "ada.fit(X_train, np.ravel(y_train))\n",
        "y_pred = ada.predict(X_test)\n",
        "y_pred_proba = ada.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# model evaluation\n",
        "[precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,ada_fpr,ada_tpr] = evaluate_model(y_test ,y_pred,y_pred_proba)\n",
        "model_report(precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve)\n",
        "plt.plot(ada_fpr,ada_tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_ADA_undersampled_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bPBrj36XUrJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 AUC Plot of LR, RF, GB, ADA"
      ],
      "metadata": {
        "id": "ZXmpcwrUYq8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(dt_fpr,dt_tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.plot(lr_fpr,lr_tpr,label=\"LR=\"+str(.787))\n",
        "plt.plot(rf_fpr,rf_tpr,label=\"RF=\"+str(.774))\n",
        "plt.plot(gb_fpr,gb_tpr,label=\"GB=\"+str(.791))\n",
        "plt.plot(ada_fpr,ada_tpr,label=\"ADA=\"+str(.787))\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_under_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VlQhxE3NYqcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.7 Voting Classifier"
      ],
      "metadata": {
        "id": "8O55j3CHXVxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# define the individual models to be used in the voting classifier\n",
        "rfc = RandomForestClassifier(criterion= 'gini', max_depth= 10, max_features= None, min_samples_leaf= 1, min_samples_split= 10, n_estimators= 10000, random_state=42)\n",
        "gbm = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_features= 'log2', n_estimators= 1000,random_state = 42 )\n",
        "ada = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 1, n_estimators= 20000,random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('gbm', gbm), ('rfc', rfc), ('ada', ada)], voting='soft')\n",
        "\n",
        "# train the voting classifier\n",
        "voting_clf.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# predictions on the test data\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "y_pred_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# model evaluation\n",
        "[precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve,fpr,tpr] = evaluate_model(y_test ,y_pred,y_pred_proba)\n",
        "model_report(precision,recall,accuracy,f1,rocauc_score,report,roc_auc_curve)\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(roc_auc_curve))\n",
        "plt.legend(loc=4)\n",
        "plt.savefig('/content/images/AUC_voting_undersampled_enn.jpeg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "leOQlfGsXdVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3 Discussion\n",
        "\n",
        "This notebook provides an idea about how the dataset was sampled, as well as training the classification models and their evaluation.\n"
      "metadata": {
        "id": "o9wOCb1jXvdM"
      }
    
  ]
}
